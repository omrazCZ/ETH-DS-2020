% -*- root: Main.tex -*-
\section{Design of Discriminant}


\subsection*{Fisher's Linear Discriminant:} 
First fit a mixture of Gaussians then \\ \(c^{*} = \argmax_w \frac{(w^T(\bar{x}_0 -\bar{x}_1))^2}{w^TS_ww}\) where \(\bar{x}_0\) and \(\bar{x}_1\) are the means of the clusters and \(S_w=\hat{Cov}(C_0) + \hat{Cov}(C_1)\) 
$\mathbb{R}^d \rightarrow \mathbb{R}^{(k-1)}$: 
$\vec{y}_i = \vec{w}_i^T\vec{x}, 1 \leq i \leq k - 1, \vec{y} = W^T\vec{x}$

{\footnotesize Criterion:} $J(W) {=} \frac{|W^T\Sigma_B W|}{|W^T\Sigma_w W|} {\stackrel{\text{\tiny 2 classes}}{=}} \frac{(m_2 - m_1)^2}{s_1^2 + s_2^2}
\rightarrow \stackrel{\text{\tiny maximize}}{\text{\tiny $d/dW = 0$}}$ \\
$\Sigma_B = \sum_i n_i (m_i-m)(m_i-m)^T$ {\tiny(Between class variance)} \\
$\Sigma_W = \sum_i \sum_{x \in X_i} (x - m_i)(x - m_i)^T$ 
{\tiny(Within class variance)} \\
$m_i = \frac{1}{n_i} \sum_{x \in X_i} x$, $m = \frac{1}{n}\sum_x x$	

solution: $\hat{w} \stackrel{\text{\tiny 2 classes}} {=} \Sigma_W^{-1} (m_1 - m_2)$